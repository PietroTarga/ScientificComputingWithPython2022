{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49 28  4 59 85]\n",
      "[49 28  4 59 85]\n",
      "[[0.81395302 0.9732212  0.97235308 0.71993355 0.00147064]\n",
      " [0.91080595 0.16205656 0.27333068 0.92593843 0.05495631]\n",
      " [0.41550259 0.44702059 0.28161638 0.94878248 0.27236277]\n",
      " [0.47472741 0.16378137 0.52373216 0.62417455 0.01584173]\n",
      " [0.22501811 0.37266248 0.33215983 0.85307816 0.17198639]]\n",
      "[[0.81395302 0.9732212  0.97235308 0.71993355 0.00147064]\n",
      " [0.91080595 0.16205656 0.27333068 0.92593843 0.05495631]\n",
      " [0.41550259 0.44702059 0.28161638 0.94878248 0.27236277]\n",
      " [0.47472741 0.16378137 0.52373216 0.62417455 0.01584173]\n",
      " [0.22501811 0.37266248 0.33215983 0.85307816 0.17198639]]\n",
      "0.81395302,0.9732212,0.97235308,0.71993355,0.00147064\n",
      "0.91080595,0.16205656,0.27333068,0.92593843,0.05495631\n",
      "0.41550259,0.44702059,0.28161638,0.94878248,0.27236277\n",
      "0.47472741,0.16378137,0.52373216,0.62417455,0.01584173\n",
      "0.22501811,0.37266248,0.33215983,0.85307816,0.17198639\n"
     ]
    }
   ],
   "source": [
    "out_file_name = \"data/data_int.txt\"\n",
    "a = str(np.random.randint(100, size = 5))\n",
    "print(a)\n",
    "\n",
    "with open(out_file_name, 'w') as outfile:\n",
    "    outfile.write(a)\n",
    "\n",
    "!type data\\data_int.txt\n",
    "\n",
    "\n",
    "out_file_name2 = \"data\\data_float.txt\"\n",
    "b = str(np.random.rand(5,5))\n",
    "print(b)\n",
    "\n",
    "with open(out_file_name2, 'w') as outfile:\n",
    "    outfile.write(b)\n",
    "\n",
    "!type data\\data_float.txt\n",
    "\n",
    "out_file_name3 = \"data\\data_float.csv\"\n",
    "with open(out_file_name2, 'r') as infile:\n",
    "    with open(out_file_name3, 'w') as outfile:\n",
    "\n",
    "        for line in infile:\n",
    "            temp = line.replace('[','').replace(']','')\n",
    "            outfile.write(','.join(temp.split()) + '\\n')\n",
    "    \n",
    "!type data\\data_float.csv\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID,JobTitle,EmailAddress,FirstNameLastName,CreditCard,CreditCardType\n",
      "\n",
      "2,Investment  Advisor,Clint_Thorpe5003@bulaffy.com,Clint Thorpe,7083-8766-0251-2345,American Express\n",
      "\n",
      "12,Retail Trainee,Phillip_Carpenter9505@famism.biz,Phillip Carpenter,3657-0088-0820-5247,American Express\n",
      "\n",
      "28,Project Manager,Russel_Graves1378@extex.org,Russel Graves,6718-4818-8011-6024,American Express\n",
      "\n",
      "39,Stockbroker,Leanne_Newton1268@typill.biz,Leanne Newton,5438-0816-4166-4847,American Express\n",
      "\n",
      "57,Budget Analyst,Tony_Giles1960@iatim.tech,Tony Giles,8130-3425-7573-7745,American Express\n",
      "\n",
      "62,CNC Operator,Owen_Allcott5125@bauros.biz,Owen Allcott,4156-0107-7210-2630,American Express\n",
      "\n",
      "68,Project Manager,Liam_Lynn3280@kideod.biz,Liam Lynn,7152-3247-6053-2233,American Express\n",
      "\n",
      "74,Dentist,Regina_Woodcock5820@yahoo.com,Regina Woodcock,0208-1753-3870-8002,American Express\n",
      "\n",
      "81,HR Specialist,Carter_Wallace9614@atink.com,Carter Wallace,4256-7201-6717-4322,American Express\n",
      "\n",
      "92,Staffing Consultant,Maia_Stark2797@jiman.org,Maia Stark,3851-1403-1734-6321,American Express\n",
      "\n",
      "97,Stockbroker,Ciara_Lomax982@bauros.biz,Ciara Lomax,3702-3440-2472-5424,American Express\n",
      "\n",
      "116,Staffing Consultant,Isabel_Ellwood1475@fuliss.net,Isabel Ellwood,3738-0882-0066-6683,American Express\n",
      "\n",
      "148,CNC Operator,Abdul_Townend2202@infotech44.tech,Abdul Townend,4224-1226-3557-3448,American Express\n",
      "\n",
      "150,Fabricator,Caleb_Poulton1735@atink.com,Caleb Poulton,8203-6875-5225-0341,American Express\n",
      "\n",
      "151,Restaurant Manager,Ronald_Lewis6777@deavo.com,Ronald Lewis,7212-0155-5014-8471,American Express\n",
      "\n",
      "154,Bellman,Faith_Seymour3829@twace.org,Faith Seymour,4170-5186-6887-6558,American Express\n",
      "\n",
      "169,Assistant Buyer,Anthony_Hancock9083@qater.org,Anthony Hancock,0832-3357-6010-6550,American Express\n",
      "\n",
      "176,Healthcare Specialist,Isabella_Willson5478@nanoff.biz,Isabella Willson,5177-4868-4623-0384,American Express\n",
      "\n",
      "182,Pharmacist,Stephanie_Darcy3298@bauros.biz,Stephanie Darcy,0264-4020-5106-5576,American Express\n",
      "\n",
      "199,Investment  Advisor,Ryan_Kennedy5565@corti.com,Ryan Kennedy,3166-6287-6242-7207,American Express\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('data/user_data.json')\n",
    "df = df[df['CreditCardType']=='American Express']\n",
    "\n",
    "out_file_name = \"data/user_data_American_Express.csv\"\n",
    "\n",
    "with open(out_file_name, 'w') as outfile:\n",
    "    outfile.write(df.to_csv(index=False))\n",
    "\n",
    "!type data\\user_data_American_Express.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/data_format.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, ``pack'' the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_OSEMN.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2da1bd3d7b0c21038c2b2938e75edf580fd1f0067631067a29a0e5011ce1535"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
